{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка файла: ./data/Положение о текущем контроле успеваемост..тета «Высшая школа  экономики».docx\n",
      "Сохранено: ./proc_data/1.txt\n",
      "Обработка файла: ./data/100723-6 Заместитель проректора Ватолкина Н.Ш. (передоверие Одоевская Е.В.).docx\n",
      "Сохранено: ./proc_data/2.txt\n",
      "Обработка файла: ./data/6.18.1-01_010923-26 Итоговый документ.docx\n",
      "Сохранено: ./proc_data/3.txt\n",
      "Обработка файла: ./data/6.18.1-01_280223-13 Итоговый документ.docx\n",
      "Сохранено: ./proc_data/4.txt\n",
      "Обработка файла: ./data/6.18-01_250624-2 Приложение 1.docx\n",
      "Сохранено: ./proc_data/5.txt\n",
      "Обработка файла: ./data/Положение+о+скидках+EPA+2019_ПУ23.05.19.docx\n",
      "Сохранено: ./proc_data/6.txt\n",
      "Обработка файла: ./data/Положение о Междурнародном ..ретного права и политики БРИКС.docx\n",
      "Сохранено: ./proc_data/7.txt\n",
      "Обработка файла: ./data/7.18.1-01_090822-1 Приложение 3.docx\n",
      "Сохранено: ./proc_data/8.txt\n",
      "Обработка файла: ./data/8.3.6.2-08_191022-1 Приложение 1.docx\n",
      "Сохранено: ./proc_data/9.txt\n",
      "Обработка файла: ./data/6.18.1-01_300721-5 Приложение 1.docx\n",
      "Сохранено: ./proc_data/10.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from docx import Document\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def convert_docx_to_txt(docx_path):\n",
    "    \"\"\"\n",
    "    Читает документ .docx и возвращает его содержимое в виде строки.\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    full_text = [para.text for para in doc.paragraphs]\n",
    "    text = \"\\n\".join(full_text)\n",
    "    return text\n",
    "\n",
    "def ocr_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Takes a .pdf document and returns extracted text\n",
    "    \"\"\"\n",
    "    os.environ['TESSDATA_PREFIX'] = '/opt/homebrew/share/tessdata'\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    extracted_text = ''\n",
    "    for i, page in enumerate(pages):\n",
    "        text = pytesseract.image_to_string(page, lang='rus+eng')\n",
    "        extracted_text += text\n",
    "    return extracted_text\n",
    "\n",
    "def get_text_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Извлекает текст из файла с поддержкой форматов .txt, .docx и .pdf.\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    ext = ext.lower()\n",
    "    \n",
    "    if ext == \".txt\":\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    elif ext == \".docx\":\n",
    "        return convert_docx_to_txt(file_path)\n",
    "    elif ext == \".pdf\":\n",
    "        return ocr_pdf(file_path)\n",
    "    else:\n",
    "        print(f\"Неподдерживаемый формат файла: {file_path}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_documents(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Обрабатывает все файлы из input_dir с расширениями .docx, .pdf и .txt,\n",
    "    извлекает из них текст и сохраняет в output_dir в виде файлов с нумерацией (1.txt, 2.txt, ...).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    file_patterns = [\"*.docx\", \"*.pdf\", \"*.txt\"]\n",
    "    files = []\n",
    "    for pattern in file_patterns:\n",
    "        files.extend(glob.glob(os.path.join(input_dir, pattern)))\n",
    "    \n",
    "    i = 0\n",
    "    for idx, file_path in enumerate(files, start=1):\n",
    "        if i > 9:\n",
    "            break\n",
    "        print(f\"Обработка файла: {file_path}\")\n",
    "        text = get_text_from_file(file_path)\n",
    "        if text and text.strip():\n",
    "            output_file = os.path.join(output_dir, f\"{idx}.txt\")\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            print(f\"Сохранено: {output_file}\")\n",
    "        else:\n",
    "            print(f\"Пустой текст или ошибка при обработке файла: {file_path}\")\n",
    "        i += 1\n",
    "\n",
    "input_directory = \"./data\" \n",
    "output_directory = \"./proc_data\"    \n",
    "\n",
    "process_documents(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка файла: ./proc_data/10.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/10.txt\n",
      "Обработка файла: ./proc_data/9.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/9.txt\n",
      "Обработка файла: ./proc_data/8.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/8.txt\n",
      "Обработка файла: ./proc_data/5.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/5.txt\n",
      "Обработка файла: ./proc_data/4.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/4.txt\n",
      "Обработка файла: ./proc_data/6.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/6.txt\n",
      "Обработка файла: ./proc_data/7.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/7.txt\n",
      "Обработка файла: ./proc_data/3.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/3.txt\n",
      "Обработка файла: ./proc_data/2.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/2.txt\n",
      "Обработка файла: ./proc_data/1.txt\n",
      "Суммаризация успешно получена для файла: ./proc_data/1.txt\n",
      "Обучающий датасет сохранён в файл: training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from usecrets import OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "prompt = \"Ты эксперт по суммаризации текста. Сформируй краткую, четкую и содержательную суммаризацию представленного текста, избегая шаблонных вводных фраз вроде 'Документ содержит' или 'В документе говорится'. Излагай все от третьего лица в нейтрально-официальном стиле. Ты должен написать не более 2-х предложений. Текст: \"\n",
    "\n",
    "def get_summary(text, max_retries=3):\n",
    "    \"\"\"\n",
    "    Отправляет текст в ChatGPT API для получения суммаризации.\n",
    "    При возникновении ошибок повторяет запрос с экспоненциальной задержкой.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            client = openai.OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"o1-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt + text}\n",
    "                ],\n",
    "                # temperature=0.3,\n",
    "                max_completion_tokens=1000\n",
    "            )\n",
    "            summary = response.choices[0].message.content.strip()\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке текста: {e}. Попытка {attempt + 1} из {max_retries}.\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    return None\n",
    "\n",
    "def generate_training_dataset(input_dir, output_file):\n",
    "    \"\"\"\n",
    "    Обходит все .txt файлы в директории input_dir, считывает их содержимое,\n",
    "    запрашивает суммаризацию через ChatGPT API и сохраняет итоговые пары {\"text\": ..., \"summary\": ...}\n",
    "    в выходной файл output_file в формате JSON Lines.\n",
    "    \"\"\"\n",
    "    txt_files = glob.glob(os.path.join(input_dir, \"*.txt\"))\n",
    "    training_data = []\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        print(f\"Обработка файла: {txt_file}\")\n",
    "        try:\n",
    "            with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка чтения файла {txt_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not text.strip():\n",
    "            print(f\"Пустой текст в файле {txt_file}. Пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        summary = get_summary(text)\n",
    "        if summary:\n",
    "            training_data.append({\n",
    "                \"text\": text,\n",
    "                \"summary\": summary\n",
    "            })\n",
    "            print(f\"Суммаризация успешно получена для файла: {txt_file}\")\n",
    "        else:\n",
    "            print(f\"Не удалось получить суммаризацию для файла: {txt_file}\")\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in training_data:\n",
    "            json_line = json.dumps(entry, ensure_ascii=False)\n",
    "            f.write(json_line + \"\\n\")\n",
    "    \n",
    "    print(f\"Обучающий датасет сохранён в файл: {output_file}\")\n",
    "\n",
    "\n",
    "input_directory = \"./proc_data\"\n",
    "output_jsonl = \"train.jsonl\"\n",
    "generate_training_dataset(input_directory, output_jsonl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это тестовый текст, предназначенный для проверки работы системы суммаризации текста.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "client = openai.OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Ты эксперт по суммаризации текста. Сформируй краткое и информативное резюме для представленного документа.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"тестовый текст\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_tokens=256\n",
    ")\n",
    "summary = response.choices[0].message.content.strip()\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
